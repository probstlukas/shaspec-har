{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Specific Encoder ----------------\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "size  torch.Size([1, 42, 45, 1])\n",
      "torch.Size([1, 42, 45, 1])\n",
      "SPECIFIC FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SPECIFIC FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SPECIFIC FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SPECIFIC FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SPECIFIC FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SPECIFIC FEATURES:  [tensor([[[-0.0494,  0.0329,  0.0546,  ..., -0.0060, -0.0299,  0.0382],\n",
      "         [-0.0348,  0.0440,  0.0480,  ...,  0.0008, -0.0058,  0.0567],\n",
      "         [-0.0378,  0.0346,  0.0426,  ..., -0.0061, -0.0183,  0.0124],\n",
      "         ...,\n",
      "         [-0.0474,  0.0212,  0.0591,  ...,  0.0131, -0.0161,  0.0415],\n",
      "         [-0.0348,  0.0367,  0.0375,  ..., -0.0015, -0.0219,  0.0390],\n",
      "         [-0.0506,  0.0318,  0.0491,  ..., -0.0017, -0.0186,  0.0379]]],\n",
      "       grad_fn=<ViewBackward0>), tensor([[[-0.0063, -0.0726,  0.0538,  ...,  0.0225, -0.0755,  0.0976],\n",
      "         [-0.0032, -0.0626,  0.0573,  ...,  0.0214, -0.0731,  0.0943],\n",
      "         [-0.0063, -0.0681,  0.0459,  ...,  0.0018, -0.0570,  0.1138],\n",
      "         ...,\n",
      "         [-0.0058, -0.0731,  0.0376,  ...,  0.0299, -0.0690,  0.0929],\n",
      "         [ 0.0009, -0.0742,  0.0478,  ...,  0.0274, -0.0701,  0.0957],\n",
      "         [ 0.0045, -0.0622,  0.0312,  ...,  0.0140, -0.0802,  0.1001]]],\n",
      "       grad_fn=<ViewBackward0>), tensor([[[ 0.0542,  0.0957,  0.0768,  ...,  0.0062, -0.0697, -0.0183],\n",
      "         [ 0.0539,  0.1019,  0.0723,  ..., -0.0096, -0.0801, -0.0126],\n",
      "         [ 0.0544,  0.0897,  0.0591,  ...,  0.0035, -0.0744, -0.0138],\n",
      "         ...,\n",
      "         [ 0.0378,  0.0962,  0.0613,  ..., -0.0216, -0.0605, -0.0328],\n",
      "         [ 0.0428,  0.0866,  0.0932,  ..., -0.0392, -0.0667, -0.0215],\n",
      "         [ 0.0685,  0.0804,  0.0867,  ..., -0.0092, -0.0734, -0.0373]]],\n",
      "       grad_fn=<ViewBackward0>), tensor([[[-0.0010,  0.0009, -0.0339,  ..., -0.0386,  0.0638,  0.0297],\n",
      "         [ 0.0155,  0.0085, -0.0306,  ..., -0.0371,  0.0688,  0.0189],\n",
      "         [ 0.0100, -0.0071, -0.0305,  ..., -0.0435,  0.0619,  0.0305],\n",
      "         ...,\n",
      "         [ 0.0089,  0.0100, -0.0314,  ..., -0.0511,  0.0677,  0.0379],\n",
      "         [ 0.0196, -0.0003, -0.0382,  ..., -0.0498,  0.0794,  0.0262],\n",
      "         [ 0.0173,  0.0078, -0.0452,  ..., -0.0331,  0.0660,  0.0254]]],\n",
      "       grad_fn=<ViewBackward0>), tensor([[[ 0.0689,  0.0197,  0.0202,  ...,  0.0569, -0.0214, -0.0249],\n",
      "         [ 0.1070,  0.0403,  0.0404,  ...,  0.0715, -0.0128, -0.0150],\n",
      "         [ 0.0752,  0.0331,  0.0575,  ...,  0.0762, -0.0028, -0.0382],\n",
      "         ...,\n",
      "         [ 0.0589,  0.0239,  0.0504,  ...,  0.0676, -0.0017, -0.0239],\n",
      "         [ 0.0645,  0.0239,  0.0475,  ...,  0.0781, -0.0100, -0.0085],\n",
      "         [ 0.0927,  0.0358,  0.0300,  ...,  0.0545, -0.0313, -0.0257]]],\n",
      "       grad_fn=<ViewBackward0>)]\n",
      "SPECIFIC FEATURES LENGTH:  5\n",
      "---------------- Shared Encoder ----------------\n",
      "size  torch.Size([1, 42, 225, 1])\n",
      "torch.Size([1, 42, 225, 1])\n",
      "size  torch.Size([1, 42, 225, 1])\n",
      "torch.Size([1, 42, 225, 1])\n",
      "size  torch.Size([1, 42, 225, 1])\n",
      "torch.Size([1, 42, 225, 1])\n",
      "size  torch.Size([1, 42, 225, 1])\n",
      "torch.Size([1, 42, 225, 1])\n",
      "size  torch.Size([1, 42, 225, 1])\n",
      "torch.Size([1, 42, 225, 1])\n",
      "SHARED FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SHARED FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SHARED FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SHARED FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SHARED FEATURE SHAPE:  torch.Size([1, 45, 84])\n",
      "SHARED FEATURES LENGTH:  5\n",
      "CONCATENATED:  torch.Size([1, 45, 168])\n",
      "PROJECTED:  torch.Size([1, 45, 84])\n",
      "--------------------------------\n",
      "torch.Size([1, 45, 84])\n",
      "torch.Size([1, 45, 84])\n",
      "MODALITY EMBEDDING:  torch.Size([1, 45, 84])\n",
      "CONCATENATED:  torch.Size([1, 45, 168])\n",
      "PROJECTED:  torch.Size([1, 45, 84])\n",
      "--------------------------------\n",
      "torch.Size([1, 45, 84])\n",
      "torch.Size([1, 45, 84])\n",
      "MODALITY EMBEDDING:  torch.Size([1, 45, 84])\n",
      "CONCATENATED:  torch.Size([1, 45, 168])\n",
      "PROJECTED:  torch.Size([1, 45, 84])\n",
      "--------------------------------\n",
      "torch.Size([1, 45, 84])\n",
      "torch.Size([1, 45, 84])\n",
      "MODALITY EMBEDDING:  torch.Size([1, 45, 84])\n",
      "CONCATENATED:  torch.Size([1, 45, 168])\n",
      "PROJECTED:  torch.Size([1, 45, 84])\n",
      "--------------------------------\n",
      "torch.Size([1, 45, 84])\n",
      "torch.Size([1, 45, 84])\n",
      "MODALITY EMBEDDING:  torch.Size([1, 45, 84])\n",
      "CONCATENATED:  torch.Size([1, 45, 168])\n",
      "PROJECTED:  torch.Size([1, 45, 84])\n",
      "--------------------------------\n",
      "torch.Size([1, 45, 84])\n",
      "torch.Size([1, 45, 84])\n",
      "MODALITY EMBEDDING:  torch.Size([1, 45, 84])\n",
      "MODALITY EMBEDDINGS:  [tensor([[[ 0.0299, -0.0650,  0.0535,  ..., -0.0607, -0.1450,  0.0361],\n",
      "         [ 0.0350, -0.0813,  0.0772,  ..., -0.0784, -0.1867,  0.0348],\n",
      "         [ 0.0373, -0.0773,  0.0693,  ..., -0.0446, -0.1533,  0.0300],\n",
      "         ...,\n",
      "         [ 0.0321, -0.0756,  0.0574,  ..., -0.0450, -0.1451,  0.0319],\n",
      "         [ 0.0373, -0.0671,  0.0834,  ..., -0.0551, -0.1581,  0.0247],\n",
      "         [ 0.0407, -0.0610,  0.0599,  ..., -0.0540, -0.1476,  0.0309]]],\n",
      "       grad_fn=<AddBackward0>), tensor([[[ 0.0810, -0.0275,  0.0049,  ..., -0.0035, -0.1304,  0.0303],\n",
      "         [ 0.0671, -0.0301,  0.0044,  ...,  0.0195, -0.1125,  0.0129],\n",
      "         [ 0.0662, -0.0405, -0.0069,  ..., -0.0071, -0.1321,  0.0057],\n",
      "         ...,\n",
      "         [ 0.0747, -0.0344, -0.0117,  ..., -0.0021, -0.1213,  0.0079],\n",
      "         [ 0.0825, -0.0338, -0.0083,  ..., -0.0102, -0.1059,  0.0003],\n",
      "         [ 0.0723, -0.0264, -0.0016,  ...,  0.0021, -0.1367, -0.0003]]],\n",
      "       grad_fn=<AddBackward0>), tensor([[[ 0.0312, -0.0441,  0.0402,  ..., -0.0484, -0.1273,  0.0355],\n",
      "         [ 0.0246, -0.0221,  0.0358,  ..., -0.0461, -0.1589,  0.0327],\n",
      "         [ 0.0243, -0.0332,  0.0231,  ..., -0.0498, -0.1459,  0.0273],\n",
      "         ...,\n",
      "         [ 0.0306, -0.0246,  0.0229,  ..., -0.0482, -0.1083,  0.0123],\n",
      "         [ 0.0246, -0.0118,  0.0334,  ..., -0.0460, -0.1383,  0.0299],\n",
      "         [ 0.0140, -0.0149,  0.0400,  ..., -0.0597, -0.1351,  0.0220]]],\n",
      "       grad_fn=<AddBackward0>), tensor([[[-0.0037, -0.0601,  0.0225,  ..., -0.0387, -0.0967, -0.0064],\n",
      "         [-0.0124, -0.0579,  0.0354,  ..., -0.0879, -0.1269,  0.0186],\n",
      "         [ 0.0028, -0.0597,  0.0247,  ..., -0.0456, -0.1075,  0.0110],\n",
      "         ...,\n",
      "         [-0.0084, -0.0562,  0.0325,  ..., -0.0590, -0.1090,  0.0245],\n",
      "         [ 0.0023, -0.0705,  0.0263,  ..., -0.0601, -0.0988,  0.0193],\n",
      "         [-0.0075, -0.0417,  0.0128,  ..., -0.0740, -0.0850,  0.0175]]],\n",
      "       grad_fn=<AddBackward0>), tensor([[[-0.0344, -0.0633,  0.0169,  ..., -0.0697, -0.1470,  0.0255],\n",
      "         [-0.0234, -0.0478,  0.0147,  ..., -0.0600, -0.1442,  0.0255],\n",
      "         [-0.0146, -0.0665,  0.0232,  ..., -0.0732, -0.1664,  0.0549],\n",
      "         ...,\n",
      "         [-0.0049, -0.0726,  0.0216,  ..., -0.0681, -0.1482,  0.0252],\n",
      "         [-0.0145, -0.0626,  0.0045,  ..., -0.0531, -0.1317,  0.0208],\n",
      "         [-0.0276, -0.0546,  0.0197,  ..., -0.0460, -0.1459,  0.0086]]],\n",
      "       grad_fn=<AddBackward0>)]\n",
      "Shape of concatenated features:  torch.Size([1, 45, 420])\n",
      "Prediction shape:  torch.Size([1, 45, 19])\n"
     ]
    }
   ],
   "source": [
    "from models.ShaSpec import SpecificEncoder, SharedEncoder, ShaSpec\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "config_file = open('configs/model.yaml', mode='r')\n",
    "config = yaml.load(config_file, Loader=yaml.FullLoader)[\"shaspec\"]\n",
    "\n",
    "# Load the configuration\n",
    "filter_num= config['filter_num']\n",
    "filter_size= config['filter_size']\n",
    "sa_div = config['sa_div']\n",
    "\n",
    "# Parameter for the model\n",
    "activation = \"ReLU\"\n",
    "decoder_type = \"FC\"\n",
    "shared_encoder_type = \"concatenated\"\n",
    "\n",
    "# Craft exemplary dataset for one subject (similar to DSADS)\n",
    "modalities_num = 5\n",
    "classes_num = 19\n",
    "num_of_sensor_channels = 45\n",
    "\n",
    "# Dummy input for each modality\n",
    "# B F T C\n",
    "input = (1, 1, 128, num_of_sensor_channels)  \n",
    "dummy_inputs = [torch.randn(input) for _ in range(modalities_num)]\n",
    "\n",
    "shaspec_model = ShaSpec(input, \n",
    "                        modalities_num,\n",
    "                        classes_num, \n",
    "                        filter_num,\n",
    "                        filter_size, \n",
    "                        sa_div,\n",
    "                        activation,\n",
    "                        decoder_type,\n",
    "                        shared_encoder_type\n",
    "                        )\n",
    "\n",
    "# Forward pass with the dummy inputs\n",
    "output = shaspec_model(dummy_inputs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
