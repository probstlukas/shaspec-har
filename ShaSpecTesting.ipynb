{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Specific Encoder ----------------\n",
      "--> batch_size, F=1, T, C\n",
      "Before applying conv layers:  torch.Size([1, 1, 128, 18])\n",
      "After applying conv layer 1:  torch.Size([1, 64, 62, 18])\n",
      "After applying conv layer 2:  torch.Size([1, 64, 29, 18])\n",
      "After applying conv layer 3:  torch.Size([1, 64, 13, 18])\n",
      "After applying conv layers:  torch.Size([1, 64, 5, 18])\n",
      "--> batch_size, F=filter_num, T*, C\n",
      "size  torch.Size([1, 64, 18, 1])\n",
      "torch.Size([1, 64, 18, 1])\n",
      "size  torch.Size([1, 64, 18, 1])\n",
      "torch.Size([1, 64, 18, 1])\n",
      "size  torch.Size([1, 64, 18, 1])\n",
      "torch.Size([1, 64, 18, 1])\n",
      "size  torch.Size([1, 64, 18, 1])\n",
      "torch.Size([1, 64, 18, 1])\n",
      "size  torch.Size([1, 64, 18, 1])\n",
      "torch.Size([1, 64, 18, 1])\n",
      "After applying self-attention:  torch.Size([1, 64, 18, 5])\n",
      "After permuting:  torch.Size([1, 18, 64, 5])\n",
      "After reshaping:  torch.Size([1, 18, 320])\n",
      "After passing through fc layer:  torch.Size([1, 18, 128])\n",
      "Specific encoder output shape: torch.Size([1, 18, 128])\n",
      "\n",
      "\n",
      "---------------- Shared Encoder ----------------\n",
      "Sha Enc input shape:  (1, 1, 128, 108)\n",
      "torch.Size([1, 1, 128, 108])\n",
      "torch.Size([1, 64, 62, 108])\n",
      "torch.Size([1, 64, 29, 108])\n",
      "torch.Size([1, 64, 13, 108])\n",
      "torch.Size([1, 64, 5, 108])\n",
      "size  torch.Size([1, 64, 108, 1])\n",
      "torch.Size([1, 64, 108, 1])\n",
      "size  torch.Size([1, 64, 108, 1])\n",
      "torch.Size([1, 64, 108, 1])\n",
      "size  torch.Size([1, 64, 108, 1])\n",
      "torch.Size([1, 64, 108, 1])\n",
      "size  torch.Size([1, 64, 108, 1])\n",
      "torch.Size([1, 64, 108, 1])\n",
      "size  torch.Size([1, 64, 108, 1])\n",
      "torch.Size([1, 64, 108, 1])\n",
      "After refined: torch.Size([1, 64, 108, 5])\n",
      "Before splitting:  torch.Size([1, 108, 128])\n",
      "Shape of modality 0 output tensor: torch.Size([1, 18, 128])\n",
      "Shape of modality 1 output tensor: torch.Size([1, 18, 128])\n",
      "Shape of modality 2 output tensor: torch.Size([1, 18, 128])\n",
      "Shape of modality 3 output tensor: torch.Size([1, 18, 128])\n",
      "Shape of modality 4 output tensor: torch.Size([1, 18, 128])\n",
      "Shape of modality 5 output tensor: torch.Size([1, 18, 128])\n"
     ]
    }
   ],
   "source": [
    "from models.ShaSpec import SpecificEncoder, SharedEncoder\n",
    "import torch\n",
    "\n",
    "# (batch_size, F=filter_num, T, C)\n",
    "# input shape for one single modality\n",
    "input_shape = (1, 1, 128, 18)  # Initial configuration\n",
    "\n",
    "# Initialize a dummy input tensor\n",
    "x_1 = torch.randn(input_shape)\n",
    "\n",
    "N = 6  # Number of modalities (devices)\n",
    "# Create a list of N tensors, each with the same shape as x_1\n",
    "modalities = [torch.randn(input_shape) for _ in range(N)]\n",
    "\n",
    "# Stack the modalities along the num_of_sensor_channels dimension\n",
    "x = torch.cat(modalities, dim=3)  # The shape of x will be [1, 1, 128, 18*N]\n",
    "\n",
    "print(\"-\"*16, \"Specific Encoder\", \"-\"*16)\n",
    "# Filter size = kernel size\n",
    "specific_encoder = SpecificEncoder(input_shape, filter_num=64, filter_size=5, activation='ReLU', sa_div=8)\n",
    "specific_output = specific_encoder(x_1)\n",
    "# Print the output shape\n",
    "print(\"Specific encoder output shape:\", specific_output.shape)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"-\"*16, \"Shared Encoder\", \"-\"*16)\n",
    "# Input shape: \n",
    "shared_encoder = SharedEncoder(N, input_shape, filter_num=64, filter_size=5, activation='ReLU', sa_div=8)\n",
    "shared_output = shared_encoder(x)\n",
    "# Print the output shape\n",
    "# Iterate over the output tuple list and print the shape of each tensor\n",
    "for i, modality_tensor in enumerate(shared_output):\n",
    "    print(f\"Shape of modality {i} output tensor:\", modality_tensor.shape)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
