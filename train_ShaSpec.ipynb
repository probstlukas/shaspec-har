{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter for training\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "\n",
    "args.to_save_path     = \"../Run_logs\"           \n",
    "args.window_save_path = \"../Sliding_window\"\n",
    "args.root_path        = \"../datasets\"\n",
    "\n",
    "args.drop_transition  = False\n",
    "# Nomalization of the data, depends on dataset!\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "args.batch_size       = 32 # Reduce if not enough graphic memory\n",
    "args.shuffle          = True # Give NN more variety to learn\n",
    "args.drop_last        = True # Drop last batch if smaller than batch size\n",
    "args.train_vali_quote = 0.90 # 90% training, 10% validation                     \n",
    "\n",
    "# Training setting \n",
    "args.train_epochs            = 60\n",
    "\n",
    "# According to ShaSpec paper\n",
    "args.learning_rate           = 0.001 # 10^(-3)\n",
    "args.learning_rate_patience  = 20 # Reduce learning rate every 20 epochs\n",
    "args.learning_rate_factor    = 0.1 # Reduce learning rate by 10%\n",
    "\n",
    "args.weight_decay            = 0.01 # 10^(-2)\n",
    "\n",
    "args.early_stop_patience     = 15 # Stop after 15 epochs without improvement\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 0 # Use first GPU\n",
    "args.use_multi_gpu           = False # Use multiple GPUs\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get content of folder args.window_save_path\n",
    "files = os.listdir(args.window_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter for data\n",
    "\n",
    "args.seed                             = 999 # Seed for reproducibility\n",
    "\n",
    "args.data_name                        = \"dsads\"\n",
    "\n",
    "# Wavelet calculates frequence parameters from time series data, don't need that\n",
    "args.wavelet_filtering                = False\n",
    "args.wavelet_filtering_regularization = False\n",
    "args.wavelet_filtering_finetuning     = False\n",
    "args.wavelet_filtering_finetuning_percent = 0.5\n",
    "args.wavelet_filtering_learnable      = False\n",
    "args.wavelet_filtering_layernorm      = False\n",
    "\n",
    "args.regulatization_tradeoff          = 0\n",
    "args.number_wavelet_filtering         = 6\n",
    "\n",
    "# Augmentation difference\n",
    "args.difference          =  False\n",
    "\n",
    "# Augmentation filtering\n",
    "args.filtering           =  False\n",
    "\n",
    "# Augmentation  magnitude\n",
    "args.magnitude           =  False\n",
    "args.weighted_sampler    = False\n",
    "\n",
    "# MIXUP\n",
    "args.mixup_probability  = 1\n",
    "args.mixup_alpha  = 0.5\n",
    "\n",
    "# Random Augmentation\n",
    "args.random_augmentation_prob = 1\n",
    "args.random_augmentation_config = {\"jitter\": True, \n",
    "                                   \"moving_average\": True,\n",
    "                                   \"magnitude_scaling\": True,\n",
    "                                   \"magnitude_warp\": True,\n",
    "                                   \"magnitude_shift\": True,\n",
    "                                   \"time_warp\": True,\n",
    "                                   \"window_warp\": True,\n",
    "                                   \"window_slice\": True,\n",
    "                                   \"random_sampling\": True,\n",
    "                                   \"slope_adding\": True\n",
    "                                   }\n",
    "random_augmentation_nr = 0\n",
    "for key in args.random_augmentation_config.keys():\n",
    "    if args.random_augmentation_config[key]:\n",
    "        random_augmentation_nr = random_augmentation_nr+1\n",
    "args.random_augmentation_nr = random_augmentation_nr\n",
    "args.max_aug = 3\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "args.exp_mode            = \"LOCV\"\n",
    "if args.data_name      ==  \"skodar\":\n",
    "    args.exp_mode            = \"SOCV\"\n",
    "    \n",
    "config_file = open('configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "args.num_modalities  =  config[\"num_modalities\"]\n",
    "args.miss_rates       =  config[\"miss_rates\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# Input information\n",
    "args.c_in            =  config[\"num_channels\"]\n",
    "# For ShaSpec we want the number of channels per modality\n",
    "args.c_in_per_mod    =  config[\"num_channels\"] // args.num_modalities\n",
    "\n",
    "args.f_in            =  1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "================  ShaSpec Model Configuration  ================\n",
      "Number of total modalities:  5\n",
      "Selected miss rate:  0.6\n",
      "Number of available modalities:  2\n",
      "Ablate shared encoder:  True\n",
      "Ablate missing modality features:  False\n",
      "Build the ShaSpec model!\n",
      "Done!\n",
      "Parameter: 325909\n",
      "Set the seed as:  999\n"
     ]
    }
   ],
   "source": [
    "### Parameter for the model\n",
    "\n",
    "args.model_type = \"shaspec\"\n",
    "\n",
    "args.miss_rate = args.miss_rates[3]\n",
    "\n",
    "args.activation = \"ReLU\"\n",
    "args.shared_encoder_type = \"concatenated\"\n",
    "\n",
    "# Ablation studies\n",
    "args.ablate_shared_encoder = True\n",
    "args.ablate_missing_modality_features = False\n",
    "\n",
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_builder(\n",
       "  (model): ShaSpec(\n",
       "    (specific_encoders): ModuleList(\n",
       "      (0-1): 2 x SpecificEncoder(\n",
       "        (be): BaseEncoder(\n",
       "          (conv_layers): Sequential(\n",
       "            (0): Conv2d(1, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "            (1): ReLU()\n",
       "            (2): Conv2d(64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "            (3): ReLU()\n",
       "            (4): Conv2d(64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "            (5): ReLU()\n",
       "            (6): Conv2d(64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "            (7): ReLU()\n",
       "          )\n",
       "          (sa): SelfAttention(\n",
       "            (query): Conv1d(64, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (key): Conv1d(64, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (value): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (fc_fusion): Linear(in_features=320, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (fc_layer): Linear(in_features=5760, out_features=19, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================  model_shaspec_data_dsads_seed_999_miss_rate_0.6_ablate_shared_encoder_True_ablate_missing_modality_features_False  ================\n",
      "================  Load all the data  ================\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "-----------------------Sliding file are generated -----------------------\n",
      "================  LOCV Mode  ================\n",
      "================  4 CV folds in total  ================\n",
      "================  CV 0  ================\n",
      "Leave one Out Experiment : The 1 Part as the test\n",
      "[-] Target sampling weights:  [0.00303951 0.00308642 0.0030303  0.003125   0.0030581  0.00307692\n",
      " 0.00308642 0.00304878 0.00307692 0.00316456 0.00315457 0.00303951\n",
      " 0.0030303  0.00310559 0.00307692 0.00307692 0.00311526 0.0031746\n",
      " 0.00308642]\n",
      "Train data number:  6156\n",
      "Validation data number:  684\n",
      "Test data number:  2280\n",
      "================  Build the shaspec model  ================\n",
      "================  ShaSpec Model Configuration  ================\n",
      "Number of total modalities:  5\n",
      "Selected miss rate:  0.6\n",
      "Number of available modalities:  2\n",
      "Ablate shared encoder:  True\n",
      "Ablate missing modality features:  False\n",
      "Build the ShaSpec model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:   0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 cost time: 290.2840099334717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:   2%|▏         | 1/60 [05:22<5:16:47, 322.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 1, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "Validation loss decreased (inf --> nan).  Saving model ...\n",
      "Epoch: 2 cost time: 289.0458514690399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:   3%|▎         | 2/60 [10:43<5:10:43, 321.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 2, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 3 cost time: 288.5684463977814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:   5%|▌         | 3/60 [16:03<5:04:56, 321.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 3, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 4 cost time: 287.9325852394104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:   7%|▋         | 4/60 [21:23<4:59:08, 320.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 4, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 5 cost time: 291.6422002315521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:   8%|▊         | 5/60 [26:46<4:54:49, 321.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 5, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 6 cost time: 288.1797640323639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:  10%|█         | 6/60 [32:06<4:48:57, 321.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 6, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 7 cost time: 288.9816219806671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:  12%|█▏        | 7/60 [37:27<4:43:32, 320.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 7, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 8 cost time: 288.27548265457153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:  13%|█▎        | 8/60 [42:47<4:37:57, 320.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 8, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 9 cost time: 287.84493041038513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:  15%|█▌        | 9/60 [48:07<4:32:20, 320.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 9, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 10 cost time: 288.0461986064911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:  17%|█▋        | 10/60 [53:27<4:26:50, 320.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 10, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 11 cost time: 288.352347612381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:  18%|█▊        | 11/60 [58:47<4:21:30, 320.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 11, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 12 cost time: 288.4551205635071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:  20%|██        | 12/60 [1:04:07<4:16:12, 320.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 12, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 13 cost time: 290.1310076713562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:  22%|██▏       | 13/60 [1:09:29<4:11:16, 320.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 13, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n",
      "Epoch: 14 cost time: 288.09931206703186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Process [epochs]:  23%|██▎       | 14/60 [1:14:49<4:05:44, 320.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALI: Epoch: 14, Steps: 193 | Train Loss: nan  Vali Loss: nan Vali Accuracy: 0.0453216  Vali weighted F1: 0.0039300  Vali macro F1 0.0045639  Vali micro F1 0.0453216\n",
      "new best score!!!!\n",
      "Validation loss decreased (nan --> nan).  Saving model ...\n",
      "new best score!!!!\n"
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
