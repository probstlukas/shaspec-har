{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from experiment import Exp\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter for training\n",
    "\n",
    "class dotdict(dict):\n",
    "    \"\"\"dot.notation access to dictionary attributes\"\"\"\n",
    "    __getattr__ = dict.get\n",
    "    __setattr__ = dict.__setitem__\n",
    "    __delattr__ = dict.__delitem__\n",
    "\n",
    "args = dotdict()   \n",
    "\n",
    "args.to_save_path     = \"../Run_logs\"           \n",
    "args.window_save_path = \"../Sliding_window\"\n",
    "args.root_path        = \"../datasets\"\n",
    "\n",
    "args.drop_transition  = False\n",
    "# Nomalization of the data, depends on dataset!\n",
    "args.datanorm_type    = \"standardization\" # None ,\"standardization\", \"minmax\"\n",
    "\n",
    "args.batch_size       = 32 # Reduce if not enough graphic memory\n",
    "args.shuffle          = True # Give NN more variety to learn\n",
    "args.drop_last        = True # Drop last batch if smaller than batch size\n",
    "args.train_vali_quote = 0.90 # 90% training, 10% validation                     \n",
    "\n",
    "# Training setting \n",
    "args.train_epochs            = 60\n",
    "\n",
    "# According to ShaSpec paper\n",
    "args.learning_rate           = 0.001 # 10^(-3)\n",
    "args.learning_rate_patience  = 20 # Reduce learning rate every 20 epochs\n",
    "args.learning_rate_factor    = 0.1 # Reduce learning rate by 10%\n",
    "\n",
    "args.weight_decay            = 0.01 # 10^(-2)\n",
    "\n",
    "args.early_stop_patience     = 15 # Stop after 15 epochs without improvement\n",
    "\n",
    "args.use_gpu                 = True if torch.cuda.is_available() else False\n",
    "args.gpu                     = 0 # Use first GPU\n",
    "args.use_multi_gpu           = False # Use multiple GPUs\n",
    "\n",
    "args.optimizer               = \"Adam\"\n",
    "args.criterion               = \"CrossEntropy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get content of folder args.window_save_path\n",
    "files = os.listdir(args.window_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter for data\n",
    "\n",
    "args.seed                             = 999 # Seed for reproducibility\n",
    "\n",
    "args.data_name                        = \"dsads\"\n",
    "\n",
    "args.pos_select       = None\n",
    "args.sensor_select    = None\n",
    "\n",
    "args.exp_mode            = \"LOCV\"\n",
    "    \n",
    "config_file = open('configs/data.yaml', mode='r')\n",
    "data_config = yaml.load(config_file, Loader=yaml.FullLoader)\n",
    "config = data_config[args.data_name]\n",
    "\n",
    "args.root_path       = os.path.join(args.root_path,config[\"filename\"])\n",
    "args.sampling_freq   = config[\"sampling_freq\"]\n",
    "args.num_classes     =  config[\"num_classes\"]\n",
    "args.num_modalities  =  config[\"num_modalities\"]\n",
    "args.miss_rates       =  config[\"miss_rates\"]\n",
    "window_seconds       = config[\"window_seconds\"]\n",
    "args.windowsize      =   int(window_seconds * args.sampling_freq) \n",
    "args.input_length    =  args.windowsize\n",
    "# Input information\n",
    "args.c_in            =  config[\"num_channels\"]\n",
    "# For ShaSpec we want the number of channels per modality\n",
    "args.c_in_per_mod    =  config[\"num_channels\"] // args.num_modalities\n",
    "\n",
    "args.f_in            =  1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use GPU: cuda:0\n",
      "================  ShaSpec Model Configuration  ================\n",
      "Number of total modalities:  5\n",
      "Selected miss rate:  0.6\n",
      "Number of available modalities:  2\n",
      "Ablate shared encoder:  False\n",
      "Ablate missing modality features:  False\n",
      "Build the ShaSpec model!\n",
      "Done!\n",
      "Parameter: 467030\n",
      "Set the seed as:  999\n"
     ]
    }
   ],
   "source": [
    "### Parameter for the model\n",
    "\n",
    "args.model_type = \"shaspec\"\n",
    "\n",
    "args.miss_rate = args.miss_rates[3]\n",
    "\n",
    "args.activation = \"ReLU\"\n",
    "args.shared_encoder_type = \"concatenated\"\n",
    "\n",
    "# Ablation studies\n",
    "args.ablate_shared_encoder = False\n",
    "args.ablate_missing_modality_features = False\n",
    "\n",
    "exp = Exp(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model_builder(\n",
       "  (model): ShaSpec(\n",
       "    (specific_encoders): ModuleList(\n",
       "      (0-1): 2 x SpecificEncoder(\n",
       "        (be): BaseEncoder(\n",
       "          (conv_layers): Sequential(\n",
       "            (0): Conv2d(1, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "            (1): ReLU()\n",
       "            (2): Conv2d(64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "            (3): ReLU()\n",
       "            (4): Conv2d(64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "            (5): ReLU()\n",
       "            (6): Conv2d(64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "            (7): ReLU()\n",
       "          )\n",
       "          (sa): SelfAttention(\n",
       "            (query): Conv1d(64, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (key): Conv1d(64, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "            (value): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          )\n",
       "          (fc_fusion): Linear(in_features=320, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (shared_encoder): SharedEncoder(\n",
       "      (be): BaseEncoder(\n",
       "        (conv_layers): Sequential(\n",
       "          (0): Conv2d(1, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "          (1): ReLU()\n",
       "          (2): Conv2d(64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "          (3): ReLU()\n",
       "          (4): Conv2d(64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "          (5): ReLU()\n",
       "          (6): Conv2d(64, 64, kernel_size=(5, 1), stride=(2, 1))\n",
       "          (7): ReLU()\n",
       "        )\n",
       "        (sa): SelfAttention(\n",
       "          (query): Conv1d(64, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (key): Conv1d(64, 8, kernel_size=(1,), stride=(1,), bias=False)\n",
       "          (value): Conv1d(64, 64, kernel_size=(1,), stride=(1,), bias=False)\n",
       "        )\n",
       "        (fc_fusion): Linear(in_features=320, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (residual_block): ResidualBlock(\n",
       "      (fc_proj): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (missing_modality_feature_generation): MissingModalityFeatureGeneration()\n",
       "    (decoder): Decoder(\n",
       "      (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "      (fc_layer): Linear(in_features=5760, out_features=19, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================  model_shaspec_data_dsads_seed_999_miss_rate_0.6_ablate_shared_encoder_False_ablate_missing_modality_features_False  ================\n",
      "================  Load all the data  ================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mexp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Bachelorarbeit/shaspec-har/experiment.py:213\u001b[0m, in \u001b[0;36mExp.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Load the data\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdata_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mexp_mode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Mode \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m)\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mnum_of_cv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m CV folds in total \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m16\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Bachelorarbeit/shaspec-har/dataloaders/dataloader_DSADS_har.py:107\u001b[0m, in \u001b[0;36mDSADS_HAR_DATA.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_activities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabelToId[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_activities]\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mno_drop_activites \u001b[38;5;241m=\u001b[39m [item \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_labels \u001b[38;5;28;01mif\u001b[39;00m item \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_activities]\n\u001b[0;32m--> 107\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mDSADS_HAR_DATA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Bachelorarbeit/shaspec-har/dataloaders/dataloader_base.py:63\u001b[0m, in \u001b[0;36mBASE_DATA.__init__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_transition        \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mdrop_transition\n\u001b[1;32m     62\u001b[0m \u001b[38;5;66;03m# ======================= Load the Data =================================\u001b[39;00m\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_all_the_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# data_x : sub_id, sensor_1, sensor_2,..., sensor_n , sub\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# data_y : activity_id   index:sub_id\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# update col_names\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_x\u001b[38;5;241m.\u001b[39mcolumns)[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Bachelorarbeit/shaspec-har/dataloaders/dataloader_DSADS_har.py:124\u001b[0m, in \u001b[0;36mDSADS_HAR_DATA.load_all_the_data\u001b[0;34m(self, root_path)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seg \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_path,action,user)):\n\u001b[1;32m    122\u001b[0m     seg_name \u001b[38;5;241m=\u001b[39m seg[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m3\u001b[39m]\n\u001b[0;32m--> 124\u001b[0m     sub_data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\u001b[43mseg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     sub_data \u001b[38;5;241m=\u001b[39msub_data\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mused_cols]\n\u001b[1;32m    126\u001b[0m     sub_data\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcol_names\n",
      "File \u001b[0;32m~/Documents/Bachelorarbeit/shaspec-har/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    945\u001b[0m )\n\u001b[1;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Bachelorarbeit/shaspec-har/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:617\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[0;32m--> 617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Bachelorarbeit/shaspec-har/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1748\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1741\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m     (\n\u001b[1;32m   1745\u001b[0m         index,\n\u001b[1;32m   1746\u001b[0m         columns,\n\u001b[1;32m   1747\u001b[0m         col_dict,\n\u001b[0;32m-> 1748\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[1;32m   1749\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1752\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/Documents/Bachelorarbeit/shaspec-har/.venv/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:236\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    234\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread_low_memory(nrows)\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_concatenate_chunks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    239\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[0;32m~/Documents/Bachelorarbeit/shaspec-har/.venv/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:369\u001b[0m, in \u001b[0;36m_concatenate_chunks\u001b[0;34m(chunks)\u001b[0m\n\u001b[1;32m    367\u001b[0m arrs \u001b[38;5;241m=\u001b[39m [chunk\u001b[38;5;241m.\u001b[39mpop(name) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunks]\n\u001b[1;32m    368\u001b[0m \u001b[38;5;66;03m# Check each arr for consistent types.\u001b[39;00m\n\u001b[0;32m--> 369\u001b[0m dtypes \u001b[38;5;241m=\u001b[39m {a\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m arrs}\n\u001b[1;32m    370\u001b[0m non_cat_dtypes \u001b[38;5;241m=\u001b[39m {x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m dtypes \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, CategoricalDtype)}\n\u001b[1;32m    372\u001b[0m dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mpop()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "exp.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
